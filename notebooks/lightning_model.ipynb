{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch Lightning implementation\n",
    "In this notebook I will implement CNN model using Pytorch Lightning.\n",
    "This model will be more flexible, than model from `initial_experiments.ipynb`, to provide more hyperparameters for training sessions.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3adf995104ba7a5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91b881c3eb328ad8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics as tm\n",
    "from typing import Type\n",
    "\n",
    "\n",
    "class RetinoCNN(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A Convolutional Neural Network (CNN) implemented using PyTorch Lightning.\n",
    "    Loss function is BCELoss, optimizer is Adam.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    conv_layers : int\n",
    "        The number of convolutional layers.\n",
    "    fc_layer_sizes : tuple of int\n",
    "        The sizes of the fully connected layers.\n",
    "    input_size : torch.Size\n",
    "        The size of the input tensor.\n",
    "    out_classes : int, optional\n",
    "        The number of output classes, default is 1 (for binary classification).\n",
    "    initial_filters : int, optional\n",
    "        The number of filters in the first convolutional layer, default is 32.\n",
    "    hl_kernel_size : int, optional\n",
    "        The kernel size for the hidden layers, default is 5.\n",
    "    activation_func : nn.Module, optional\n",
    "        The activation function to use, default is nn.ReLU.\n",
    "    max_pool_kernel : int, optional\n",
    "        The kernel size for max pooling, default is 2.\n",
    "    dropout_conv : bool, optional\n",
    "        Whether to apply dropout to the convolutional layers, default is False.\n",
    "    dropout_fc : bool, optional\n",
    "        Whether to apply dropout to the fully connected layers, default is False.\n",
    "    dropout_rate : float, optional\n",
    "        The dropout rate, default is 0.5.\n",
    "    initial_learning_rate : float, optional\n",
    "        The initial learning rate, default is 0.01.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            conv_layers: int,\n",
    "            fc_layer_sizes: tuple[int, ...],\n",
    "            input_size: torch.Size,\n",
    "            out_classes: int = 1,\n",
    "            initial_filters: int = 32,\n",
    "            hl_kernel_size: int = 5,\n",
    "            activation_func: Type[nn.Module] = nn.ReLU,\n",
    "            max_pool_kernel: int = 2,\n",
    "            dropout_conv: bool = False,\n",
    "            dropout_fc: bool = False,\n",
    "            dropout_rate: float = 0.5,\n",
    "            initial_learning_rate: float = 0.01,\n",
    "            loss_func: nn.Module = nn.BCEWithLogitsLoss(),\n",
    "    ) -> None:\n",
    "        \n",
    "        # Validate inputs before calling super().__init__()\n",
    "        self._validate_required_inputs(conv_layers, fc_layer_sizes, input_size)\n",
    "        self._validate_default_inputs(\n",
    "            out_classes,\n",
    "            initial_filters,\n",
    "            hl_kernel_size,\n",
    "            max_pool_kernel,\n",
    "            dropout_conv,\n",
    "            dropout_fc,\n",
    "            dropout_rate,\n",
    "            initial_learning_rate,\n",
    "        )\n",
    "        super().__init__()\n",
    "        \n",
    "        device = \"mps\"\n",
    "\n",
    "        # Initialize hyperparameters\n",
    "        self._initial_learning_rate = initial_learning_rate\n",
    "\n",
    "        self.loss_func = loss_func.to(device)\n",
    "\n",
    "        # Initialize metrics\n",
    "        self.accuracy = tm.Accuracy(task=\"binary\").to(device)\n",
    "        self.precision = tm.Precision(task=\"binary\").to(device)\n",
    "        self.recall = tm.Recall(task=\"binary\").to(device)\n",
    "        self.f1 = tm.F1Score(task=\"binary\").to(device)\n",
    "        self.auc = tm.AUROC(task=\"binary\").to(device)\n",
    "        self.confmat = tm.ConfusionMatrix(task=\"binary\", num_classes=2).to(device)\n",
    "\n",
    "        # Initialize convolutional layers}\n",
    "        hidden_layers = []\n",
    "        in_channels = input_size[0]\n",
    "\n",
    "        for i in range(conv_layers):\n",
    "            out_channels = initial_filters * 2 ** i\n",
    "            hidden_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=hl_kernel_size, padding=1, device=device))\n",
    "            hidden_layers.append(activation_func())\n",
    "            hidden_layers.append(nn.MaxPool2d(max_pool_kernel))\n",
    "            in_channels = out_channels\n",
    "            if dropout_conv:\n",
    "                hidden_layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers)\n",
    "\n",
    "        # Initialize fully connected layers\n",
    "        in_features = self._get_conv_out_shape(input_size)\n",
    "        fc_layers = [nn.Flatten()]\n",
    "        for out_features in fc_layer_sizes:\n",
    "            fc_layers.append(nn.Linear(in_features, out_features, device=device))\n",
    "            fc_layers.append(activation_func())\n",
    "            if dropout_fc:\n",
    "                fc_layers.append(nn.Dropout(dropout_rate))\n",
    "            in_features = out_features\n",
    "        \n",
    "        fc_layers.extend([\n",
    "                nn.Linear(in_features, out_classes, device=device),\n",
    "            ])\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(*fc_layers)    \n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            The input tensor\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The output tensor\n",
    "        \"\"\"\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Training step of the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : torch.Tensor\n",
    "            The input batch\n",
    "        batch_idx : int\n",
    "            The index of the batch\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss\n",
    "        \"\"\"\n",
    "        \n",
    "        x, y = batch\n",
    "        x = x.to(\"mps\")\n",
    "        y = y.to(\"mps\")\n",
    "        y = torch.unsqueeze(y, 1).float()\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss_func(y_pred, y)\n",
    "        \n",
    "        # self.accuracy(y_pred, y)\n",
    "        # self.precision(y_pred, y)\n",
    "        # self.recall(y_pred, y)\n",
    "        # self.f1(y_pred, y)\n",
    "        # self.auc(y_pred, y)\n",
    "        # self.confmat(y_pred, y)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Validation step of the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : torch.Tensor\n",
    "            The input batch\n",
    "        batch_idx : int\n",
    "            The index of the batch\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        x = x.to(\"mps\")\n",
    "        y = y.to(\"mps\")\n",
    "        y = torch.unsqueeze(y, 1).float()\n",
    "        y_pred = self(x)\n",
    "        \n",
    "        loss = self.loss_func(y_pred, y)\n",
    "        self.log(\"valid_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        \n",
    "        self.accuracy(y_pred, y)\n",
    "        self.precision(y_pred, y)\n",
    "        self.recall(y_pred, y)\n",
    "        self.f1(y_pred, y)\n",
    "        self.auc(y_pred, y)\n",
    "        self.confmat(y_pred, y)\n",
    "        \n",
    "        self.log(\"valid_accuracy\", self.accuracy, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"valid_precision\", self.precision, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"valid_recall\", self.recall, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"valid_f1\", self.f1, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"valid_auc\", self.auc, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Test step of the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : torch.Tensor\n",
    "            The input batch\n",
    "        batch_idx : int\n",
    "            The index of the batch\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        x = x.to(\"mps\")\n",
    "        y = y.to(\"mps\")\n",
    "        y = torch.unsqueeze(y, 1).float()\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss_func(y_pred, y)\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        \n",
    "        self.accuracy(y_pred, y)\n",
    "        self.precision(y_pred, y)\n",
    "        self.recall(y_pred, y)\n",
    "        self.f1(y_pred, y)\n",
    "        self.auc(y_pred, y)\n",
    "        self.confmat(y_pred, y)\n",
    "        \n",
    "        self.log(\"test_accuracy\", self.accuracy, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"test_precision\", self.precision, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"test_recall\", self.recall, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"test_f1\", self.f1, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"test_auc\", self.auc, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
    "        \"\"\"\n",
    "        Configure the optimizer for the model.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.optim.Optimizer\n",
    "            The optimizer\n",
    "        \"\"\"\n",
    "        return torch.optim.Adam(self.parameters(), lr=self._initial_learning_rate)\n",
    "    \n",
    "\n",
    "    def _get_conv_out_shape(self, input_size: torch.Size) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate shape of the output of the convolutional layers.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : torch.Size\n",
    "            The size of the input tensor\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Size\n",
    "            The size of the output tensor\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            zeros = torch.zeros(*input_size, device=\"mps\")\n",
    "            z = self.hidden_layers(zeros)\n",
    "            z = torch.prod(torch.tensor(z.shape))\n",
    "        return z\n",
    "\n",
    "    def _validate_required_inputs(self, conv_layers, fc_layer_sizes, input_size) -> None:\n",
    "        \"\"\"Validate inputs with no default values.\"\"\"\n",
    "\n",
    "        if not isinstance(conv_layers, int) or conv_layers < 1:\n",
    "            raise ValueError(\"conv_layers must be an integer greater than 0.\")\n",
    "\n",
    "        if not isinstance(fc_layer_sizes, tuple) or not all(isinstance(i, int) for i in fc_layer_sizes):\n",
    "            raise ValueError(\"fc_layer_sizes must be a tuple of integers.\")\n",
    "\n",
    "        if not isinstance(input_size, torch.Size):\n",
    "            raise ValueError(\"input_size must be a torch.Size object.\")\n",
    "    \n",
    "    \n",
    "    def _validate_default_inputs(self, out_classes, initial_filters, hl_kernel_size, max_pool_kernel, dropout_conv, dropout_fc, dropout_rate, initial_learning_rate) -> None:\n",
    "        \"\"\"Validate inputs with default values.\"\"\"\n",
    "\n",
    "        if not isinstance(out_classes, int) or out_classes < 1:\n",
    "            raise ValueError(\"out_classes must be an integer greater than 0.\")\n",
    "\n",
    "        if not isinstance(initial_filters, int) or initial_filters < 1:\n",
    "            raise ValueError(\"initial_filters must be an integer greater than 0.\")\n",
    "\n",
    "        if not isinstance(hl_kernel_size, int) or hl_kernel_size < 1:\n",
    "            raise ValueError(\"hl_kernel_size must be an integer greater than 0.\")\n",
    "\n",
    "        if not isinstance(max_pool_kernel, int) or max_pool_kernel < 1:\n",
    "            raise ValueError(\"max_pool_kernel must be an integer greater than 0.\")\n",
    "\n",
    "        if not isinstance(dropout_conv, bool):\n",
    "            raise ValueError(\"dropout_conv must be a boolean.\")\n",
    "\n",
    "        if not isinstance(dropout_fc, bool):\n",
    "            raise ValueError(\"dropout_fc must be a boolean.\")\n",
    "\n",
    "        if not isinstance(dropout_rate, float) or not 0 <= dropout_rate <= 1:\n",
    "            raise ValueError(\"dropout_rate must be a float between 0 and 1.\")\n",
    "\n",
    "        if not isinstance(initial_learning_rate, float) or initial_learning_rate <= 0:\n",
    "            raise ValueError(\"initial_learning_rate must be a float greater than 0.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T17:36:54.048069Z",
     "start_time": "2024-03-22T17:36:54.036606Z"
    }
   },
   "id": "910878ec04f8bc57",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "956010a1eb919f26"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "class ImageDataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir: str|Path, batch_size: int = 32, transformations: transforms.Compose = None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transformations = transformations\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = ImageFolder(root=str(Path(self.data_dir, 'train')), transform=self.transformations)\n",
    "        self.val_dataset = ImageFolder(root=str(Path(self.data_dir, 'val')), transform=self.transformations)\n",
    "        self.test_dataset = ImageFolder(root=str(Path(self.data_dir, 'test')), transform=self.transformations)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=8, persistent_workers=True, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=8, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=8, persistent_workers=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T17:36:54.516146Z",
     "start_time": "2024-03-22T17:36:54.512387Z"
    }
   },
   "id": "dad0e628113b9f1",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "root_data = os.getenv(\"KAGGLE_FILES_DIR\")\n",
    "dataset_path = Path(os.getcwd(), \"..\", root_data, 'processed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T17:36:54.814358Z",
     "start_time": "2024-03-22T17:36:54.810724Z"
    }
   },
   "id": "ade0deafc00e55c9",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "datamodule = ImageDataModule(data_dir=dataset_path, batch_size=32, transformations=transformations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T17:36:55.162098Z",
     "start_time": "2024-03-22T17:36:55.159937Z"
    }
   },
   "id": "cd8c519738c58874",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "1st model: default parameters:\n",
    "- conv_layers: 5\n",
    "- fc_layer_sizes: (256, 128)\n",
    "- input_size: torch.Size([3, 256, 256])\n",
    "- out_classes: 1\n",
    "- initial_filters: 32\n",
    "- hl_kernel_size: 5\n",
    "- activation_func: nn.ReLU\n",
    "- max_pool_kernel: 2\n",
    "- dropout_conv: False\n",
    "- dropout_fc: False\n",
    "- dropout_rate: 0.5\n",
    "- initial_learning_rate: 0.01\n",
    "- loss_func: nn.BCEWithLogitsLoss\n",
    "- optimizer: Adam\n",
    "- metrics: Accuracy, Precision, Recall, F1, AUC, ConfusionMatrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3ac0a2ca5c06f04"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model_base = RetinoCNN(\n",
    "    conv_layers=5,\n",
    "    fc_layer_sizes=(256, 128),\n",
    "    input_size=torch.Size([3, 256, 256]),\n",
    ")\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='valid_loss',\n",
    "    dirpath='../model_base',\n",
    "    filename='models-{epoch:02d}-{valid_loss:.2f}',\n",
    "    save_top_k=2,\n",
    "    mode='min') \n",
    "\n",
    "early_stopping = pl.callbacks.EarlyStopping(\n",
    "    monitor='valid_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    callbacks=[checkpoint_callback, early_stopping]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T12:20:39.272729Z",
     "start_time": "2024-03-19T12:20:39.057845Z"
    }
   },
   "id": "4bdcf59ebe481afb",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "datamodule.setup()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T12:20:39.770316Z",
     "start_time": "2024-03-19T12:20:39.392Z"
    }
   },
   "id": "b4e3eb0fcaa7753d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isulim/Sages/retino-cnn/.venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /Users/isulim/Sages/retino-cnn/model_base exists and is not empty.\n",
      "\n",
      "  | Name          | Type                  | Params\n",
      "--------------------------------------------------------\n",
      "0 | loss_func     | BCEWithLogitsLoss     | 0     \n",
      "1 | accuracy      | BinaryAccuracy        | 0     \n",
      "2 | precision     | BinaryPrecision       | 0     \n",
      "3 | recall        | BinaryRecall          | 0     \n",
      "4 | f1            | BinaryF1Score         | 0     \n",
      "5 | auc           | BinaryAUROC           | 0     \n",
      "6 | confmat       | BinaryConfusionMatrix | 0     \n",
      "7 | hidden_layers | Sequential            | 4.4 M \n",
      "8 | fc_layers     | Sequential            | 2.1 M \n",
      "--------------------------------------------------------\n",
      "6.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 M     Total params\n",
      "25.943    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "454b6cc1f33a437fbc82647a7558aee5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isulim/Sages/retino-cnn/.venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c689f9cc978f49038a2988625cf4b97b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce2fdc4446884f31ba82da5eb361b7b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isulim/Sages/retino-cnn/.venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "Metric valid_loss improved. New best score: 0.596\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4eaafbafbfc4cccbd7f4ad9d349d912"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_loss improved by 0.005 >= min_delta = 0.001. New best score: 0.590\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfc8b58289874fcf92b4549ae57c6cb6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_loss improved by 0.002 >= min_delta = 0.001. New best score: 0.588\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07867155946d4485a21c38967e535760"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "409f5629e9f642528a4a10a55bb0b6c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_loss improved by 0.002 >= min_delta = 0.001. New best score: 0.586\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cac97f6dc7943a8bb93932290a6a6af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5715f6ea4b1149ab80817b73e4244b34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "750b9926bd064d1ea5e7c13aaa8369a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c175157206c485daad08cf76cf3cadf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "197fb1527f314cdda7aaa9dbf6867c01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_loss did not improve in the last 5 records. Best score: 0.586. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model_base, datamodule)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:24:39.250321Z",
     "start_time": "2024-03-19T12:20:40.315787Z"
    }
   },
   "id": "4d06b6d2104f8277",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65a213c7e78a428887c3b110d20ef6db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.7269185185432434\n",
      "        test_auc                    0.0\n",
      "         test_f1                    0.0\n",
      "        test_loss           0.5865596532821655\n",
      "     test_precision                 0.0\n",
      "       test_recall                  0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 0.5865596532821655,\n  'test_accuracy': 0.7269185185432434,\n  'test_precision': 0.0,\n  'test_recall': 0.0,\n  'test_f1': 0.0,\n  'test_auc': 0.0}]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model_base, datamodule)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:48:56.091736Z",
     "start_time": "2024-03-19T14:47:37.528382Z"
    }
   },
   "id": "4eb4aa78f92babc3",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Baseline is established."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e8662e2fa22c59"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type                  | Params\n",
      "--------------------------------------------------------\n",
      "0 | loss_func     | BCEWithLogitsLoss     | 0     \n",
      "1 | accuracy      | BinaryAccuracy        | 0     \n",
      "2 | precision     | BinaryPrecision       | 0     \n",
      "3 | recall        | BinaryRecall          | 0     \n",
      "4 | f1            | BinaryF1Score         | 0     \n",
      "5 | auc           | BinaryAUROC           | 0     \n",
      "6 | confmat       | BinaryConfusionMatrix | 0     \n",
      "7 | hidden_layers | Sequential            | 17.5 M\n",
      "8 | fc_layers     | Sequential            | 1.1 M \n",
      "--------------------------------------------------------\n",
      "18.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "18.5 M    Total params\n",
      "74.182    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06cf9ef9604f408aafbe2a72c5463fc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82b494dc60fb4c4f94774e3fc065f6c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69fc2b8d9ac7467eb03a769fbb196c57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isulim/Sages/retino-cnn/.venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "Metric valid_loss improved. New best score: 0.676\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4410897bbc344a3f8c7e0598d106a4d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_loss improved by 0.008 >= min_delta = 0.001. New best score: 0.668\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a6736f7bbec4b6dbc5d697261ce8840"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric valid_loss improved by 0.068 >= min_delta = 0.001. New best score: 0.601\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52f09431dc2d41adbe3744d1c24bf750"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "622a0d61c0fa4262b7f0bfc8844ed0d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "159254baf46a4e3c8f21717f430757b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d48670ec3e44579b5c2cf0356648446"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cf88c9e7c64498fa49aa2f30ce720ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric valid_loss did not improve in the last 5 records. Best score: 0.601. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "model_base = RetinoCNN(\n",
    "    conv_layers=6,\n",
    "    fc_layer_sizes=(256, 128),\n",
    "    input_size=torch.Size([3, 256, 256]),\n",
    "    initial_filters=32,\n",
    "    out_classes=1,\n",
    "    hl_kernel_size=5,\n",
    "    max_pool_kernel=2,\n",
    "    dropout_conv=True,\n",
    "    dropout_fc=True,\n",
    "    dropout_rate=0.4,\n",
    "    initial_learning_rate=0.01\n",
    ")\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='valid_loss',\n",
    "    dirpath='../model_6-256-32-drop-04',\n",
    "    filename='models-{epoch:02d}-{valid_loss:.2f}',\n",
    "    save_top_k=2,\n",
    "    mode='min') \n",
    "\n",
    "early_stopping = pl.callbacks.EarlyStopping(\n",
    "    monitor='valid_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    callbacks=[checkpoint_callback, early_stopping]\n",
    ")\n",
    "trainer.fit(model_base, datamodule)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T20:01:25.773175Z",
     "start_time": "2024-03-22T17:38:51.368354Z"
    }
   },
   "id": "b4b7d9e48c95c4df",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81d7e6fa46bf4f38924656fdbd2b5aa5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.7269185185432434\n",
      "        test_auc                    0.0\n",
      "         test_f1                    0.0\n",
      "        test_loss           0.6162883043289185\n",
      "     test_precision                 0.0\n",
      "       test_recall                  0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 0.6162883043289185,\n  'test_accuracy': 0.7269185185432434,\n  'test_precision': 0.0,\n  'test_recall': 0.0,\n  'test_f1': 0.0,\n  'test_auc': 0.0}]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model_base, datamodule)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T20:02:52.598903Z",
     "start_time": "2024-03-22T20:01:25.778925Z"
    }
   },
   "id": "f3df51b7a601a28b",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "128d0b4d5c0454ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
